---
title: "Multidimensional Scaling"
author: "Pulong Ma"
date: "`r Sys.Date()`"
output: html_document
---


```{r setup, include=FALSE}

knitr::opts_chunk$set(root.dir="~/Documents/Teaching/Fall2024/STAT475_575/Data/")

library(ggplot2)
library(patchwork)
library(MASS)

```
MNIST Data
===

```{r}
library(dslabs)
mnist <- read_mnist() # A list with two components: train and test
# Each of these is a list with two components: images and labels.
# The images component is a matrix with each column representing one of the 28*28=784 pixels. The values are integers between 0 and 255 representing grey scale. The labels component is a vector representing the digit shown in the image.
X = mnist$train$images[1:1000,]
Digit = as.factor(mnist$train$labels[1:1000])

i <- 5
image(1:28, 1:28, matrix(mnist$test$images[i,], nrow=28)[ , 28:1], 
    col = gray(seq(0, 1, 0.05)), xlab = "", ylab="")


library(reshape2)
library(ggplot2)


plot.mnist <- function(im){
  #im[im<0]<-0 # set any negative intensities to zero
  #im[im>1]<-1 # set an intensities bigger than 1 to 1.
  
  
  if(is.vector(im)){ # a single image
    
    A<-matrix(im, nr=28, byrow=F)
    C<- melt(A, varnames = c("x", "y"), 
             value.name = "intensity")
    p<-ggplot(C, aes(x = x, y = y, fill = intensity))+
      geom_tile(aes(fill=intensity))+
      scale_fill_gradient(low='white', high='black')+
      scale_y_reverse()+theme(
        strip.background = element_blank(),
        strip.text.x = element_blank(),
        panel.spacing = unit(0, "lines"),
        axis.text = element_blank(),
        axis.ticks = element_blank()
      ) 
  }
  else{
    if (dim(im)[2]!=784){
      im = t(im)
    } 
    n <- dim(im)[1]
    As <- array(im, dim = c(n, 28, 28))
    
    Cs<- melt(As, varnames = c("image","x", "y"), 
              value.name = "intensity")
    p<-ggplot(Cs, aes(x = x, y = y, fill = intensity))+
      geom_tile(aes(fill=intensity))+
      scale_fill_gradient(low='white', high='black')+
      facet_wrap(~ image, nrow = floor(sqrt(n))+1, 
                 ncol = ceiling(sqrt(n))+1)+
      scale_y_reverse()+theme(
        strip.background = element_blank(),
        strip.text.x = element_blank(),
        panel.spacing = unit(0, "lines"),
        axis.text = element_blank(),
        axis.ticks = element_blank()
      ) 
    
  }
  return(p)
}

plot.mnist(X[1:8,]) + xlab("") + ylab("")
```

PCA
=== 
```{r}
# the option rank=2 can significantly speeds up the computation
mnist.pca = prcomp(X, rank=2)
g.pca=ggplot(as.data.frame(mnist.pca$x), 
       aes(x=PC1, y=PC2, colour=Digit, label=Digit))+
geom_text(aes(label=Digit))
print(g.pca)
```

Classic MDS
```{r}
# create a proximity matrix of Euclidean Distances
D = dist(X)

# Apply classical multidimensional scaling
# Note that only the first five eigenvalues are non-zero
mds1 <- cmdscale(D)
mds1.df = as.data.frame(cmdscale(D))

g.mds1=ggplot(mds1.df, aes(x=V1, y=V2, color=Digit, label=Digit)) + 
  geom_text(aes(label=Digit)) + ggtitle("Classical MDS for MNIST") + 
  xlab("Coordinate 1") + ylab("Coordinate 2")

#ggsave("~/Documents/Teaching/STAT475_575/Fall2024/Lecture08/figures/MNIST_Classical.png", width=10, height=6, dpi=400)
```


Non-metrical MDS
===
```{r}
mds2 <- isoMDS(D)
mds2.df = as.data.frame(mds2)
g.mds2=ggplot(mds2.df, aes(x=points.1, y=points.2, color=Digit, label=Digit)) + 
  geom_text(aes(label=Digit)) + ggtitle("Non-metric MDS for MNIST") + 
  xlab("V1") + ylab("V2")
wrap_plots(g.mds1, g.mds2)

```


## iris data 

```{r}
# Load the iris data set 
data(iris) 
head(iris)

# Perform MDS analysis 
mds_iris <- cmdscale(dist(iris[,1:4])) 
summary(mds_iris)
# Plot the results 
plot(mds_iris[,1], mds_iris[,2], 
	type = "n", xlab = "MDS Dimension 1", 
	ylab = "MDS Dimension 2") 

# Plot the points and label them with 
# the first two letters of the species name 
points(mds_iris[,1], mds_iris[,2], 
	pch = 21, bg = "lightblue") 
text(mds_iris[,1], mds_iris[,2], 
	labels = substr(iris$Species, 1, 2), 
	pos = 3, cex = 0.8) 

# Form clusters 
#clusters <- some_cluster_function(mds_iris) 

# Add the cluster information to the plot 
#points(mds_iris[,1], mds_iris[,2], pch = 21, bg = clusters, cex = 1.2) 

```


```{r}
# Load the USArrests data set 
data(USArrests) 

head(USArrests)

# Calculate the distance matrix 
distance_matrix <- dist(USArrests) 

# Perform MDS analysis using 
# the distance matrix 
mds_usarrests <- cmdscale(distance_matrix) 

head(mds_usarrests)
# Plot the results 
plot(mds_usarrests[,1], mds_usarrests[,2], 
	type = "n") 
text(mds_usarrests[,1], mds_usarrests[,2], 
	labels = row.names(USArrests)) 

plot(mds_usarrests[,1], mds_usarrests[,2], 
	type = "p") 
```


Some questions:
===

- How do we find such latent variables?
- How many variables should we keep?
- How is it different from PCA?

MSD
- Can use Euclidean distance
- Can use any similarity/dis-similarity matrix 

Example in Sec. 4.4.2 of Everitt \& Hothon
===
```{r}
setwd("~/Documents/Teaching/STAT475_575/Fall2024/Data/")
# the data has 10 observations and 5 variables
 mdsex1 <- read.table(file="mdsex1.txt",
        header=F, col.names=c("y1", "y2", "y3", "y4", "y5"))
head(mdsex1)

# create a proximity matrix of Euclidean Distances
D = dist(mdsex1)

# Apply classical multidimensional scaling
# Note that only the first five eigenvalues are non-zero
X <- cmdscale(D, k=9, eig=TRUE)

head(X)

# Confirm that the original distances reproduced by
# the 5-dimensional solution
  max(abs(D-dist(cmdscale(D, k=5))))

#  Compute the PM1 criterion
   pm1 <- cumsum(abs(X$eig)) / sum(abs(X$eig))
   pm1
   
# It appears that 3-dimensional coordinates provide
# a good approximation
   Xpoints <-  X$points[ , 1:3]
   
```
```{r}
# Display the first two coordinates
 #par(pch=5,fin=c(5,5))
   x <- Xpoints[ ,1]
   y <- Xpoints[ ,2]
   plot( x, y, , xlab="Coordinate 1", ylab="Coordinate 2",
         xlim=range(x)*1.2, ylim=range(y)*1.2, type="n")
   text(x, y, labels = rownames(mdsex1), cex=1.1)

# Display the coordinates two and three
 #par(pch=5,fin=c(5,5))
   x <- Xpoints[ ,2]
   y <- Xpoints[ ,3]
   plot( x, y, , xlab="Coordinate 2", ylab="Coordinate 3",
         xlim=range(x)*1.2, ylim=range(y)*1.2, type="n")
   text(x, y, labels = rownames(mdsex1), cex=1.1)
   
```


Airline Distance Example
===
```{r}
setwd("~/Documents/Teaching/STAT475_575/Fall2024/Data/")
adist <- read.table(file="airdist.txt", header=T )
head(adist)

# Create a proximity matrix
D <- as.matrix(adist)
rownames(D) <- colnames(adist)

# Apply classical multidimensional scaling
X <- cmdscale(D, k=9, eig=TRUE)
X

#  Compute the PM1 and PM2 criteria
pm1 <- cumsum(abs(X$eig)) / sum(abs(X$eig))

pm2 <- cumsum(abs(X$eig)**2) / sum(abs(X$eig)**2)

# It appears that 2-dimensional coordinates provide
 # a good approximation
  Xpoints <-  X$points[ , 1:2]

# Display the first two coordinates
   par(fin=c(4,4))
   x <- Xpoints[ ,1]
   y <- Xpoints[ ,2]
plot( x, y, xlab="Dimension 1", ylab="Dimension 2",
         xlim=range(x)*1.2, ylim=range(y)*1.2, type="n")
text(x, y, labels = rownames(D), cex=0.7)


```


House of Representatives Voting
===

```{r}
setwd("~/Documents/Teaching/STAT475_575/Fall2024/Data/")
repvote <- read.table(file="repvoting.txt", header=FALSE)

#Create a dissimilarity matrix
# Use the names in the first column
    D <- as.matrix(repvote[, -1 ])
    rownames(D) <- repvote[ , 1]
    colnames(D) <- rownames(D)

 # Apply non-metric scaling
 # First attach the MASS library
    library("MASS")
    X <- isoMDS(D)

X

# Display the first two coordinates
   par(fin=c(3.5,3.5))
   x <- X$points[ ,1]
   y <- X$points[ ,2]
   plot( x, y, , xlab="Coordinate 1", ylab="Coordinate 2",
         xlim=range(x)*1.1, ylim=range(y)*1.1, type="n")
text(x, y, labels = rownames(D), cex=0.4)

# Create a Shepard Diagram
voting_sh <- Shepard(D[lower.tri(D)], X$points)
plot(voting_sh, pch=".", xlab="Dissimilarity",
     ylab="Distance", xlim=range(voting_sh$x)*1.1,
     ylim=range(voting_sh$x)*1.1)
lines(voting_sh$x, voting_sh$yf, type="S")

```

- Separation is mainly along party lines with Democrats on the  right side of the display.
- One Republication, Rinaldo, has a voting record similar to  the  Democrats on environmental issues.
- The Republicans exhibit more variation than the Democrats.
- The two congressmen with the most abstentions, Sandman(R) 
and Thompson(R), are both in the upper portion of the 
 display.
- Stress is 9.88\% which is an indication of a moderately good 
 representation.  This is supported by the Shepard diagram.


Stress
===

- Stress is the goodness-of-fit statistic that MDS tries to minimize. 
- Stress consists of the square root of normalized discrepancies between interpoint distances in the MDS plot and the smoothed distances predicted from the dissimilarities. 
- Stress varies between 0 and 1, with values near 0 indicating better fit.

The Shepard Diagram
===

- The Shepard diagram is a scatterplot of the distances between points in the MDS against the observed dissimilarities (or similarities).
- The points in the plot should adhere clearly to a curve or straight line (which would be the smoothed distances).




