---
title: "Model-based Clustering"
author: "Pulong Ma"
date: "`r Sys.Date()`"
output: html_document
---


```{r setup, include=FALSE}

knitr::opts_chunk$set(root.dir="~/Documents/Teaching/Fall2023_STAT475-575/Data/")

library(ggplot2)
library(patchwork)
```

# Flip a fair coin

- If it comes up heads: Generate a random number from a normal distribution with mean 1 and variance 0.25.
- If it comes up tails: Generate a random number from a normal distribution with mean 3 and variance 0.25.

- The density function for a normal random variable can be written explicitly. We usually call it
$$
\phi(x) = \frac{1}{\sigma \sqrt{2\pi}} \exp\left\{- \frac{(x-\mu)^2}{2\sigma^2} \right\}.
$$

```{r}
coinflips = (runif(10000) > 0.5)
table(coinflips)

oneFlip = function(fl, mean1 = 1, mean2 = 3, sd1 = 0.5, sd2 = 0.5) {
  if (fl) {
   rnorm(1, mean1, sd1)
  } else {
   rnorm(1, mean2, sd2)
  }
}
fairmix = vapply(coinflips, oneFlip, numeric(1))
library("ggplot2")
library("dplyr")
gg0 = ggplot(tibble(value = fairmix), aes(x = value)) +
     geom_histogram(fill = "purple", binwidth = 0.1) + xlab("x")
print(gg0)
```


# Visualizing a Gaussian finite mixture model

$$
f(x) = \frac{1}{2}\phi_1(x) + \frac{1}{2} \phi_2(x),
$$
where $\phi_1$ is the density of the normal distribution $N(\mu_1=1, \sigma^2=0.25)$ and $\phi_1$ is density of the normal distribution $N(\mu_1=3, \sigma^2=0.25)$

```{r}
means = c(1, 3)
sds = c(0.5, 0.5)
fairtheory = tibble(
  x = seq(-1, 5, length.out = 1000),
  f = 0.5 * dnorm(x, mean = means[1], sd = sds[1]) +
      0.5 * dnorm(x, mean = means[2], sd = sds[2]))

gg1 = ggplot(fairtheory, aes(x = x, y = f)) +
  geom_line(color = "red", linewidth = 1.5) + ylab("mixture density")
gg1
```



# More than two components
```{r}
masses = c(A =  331, C =  307, G =  347, T =  322)
probs  = c(A = 0.12, C = 0.38, G = 0.36, T = 0.14)
N  = 7000
sd = 3
nuclt   = sample(length(probs), N, replace = TRUE, prob = probs)
quadwts = rnorm(length(nuclt),
                mean = masses[nuclt],
                sd   = sd)
gg2 = ggplot(tibble(quadwts = quadwts), aes(x = quadwts)) +
  geom_histogram(bins = 100, fill = "purple") + xlab("x")
gg2
```

```{r, include=FALSE, eval=FALSE}
pdf(file = "mixture_examples.pdf", width=10, height=4)
wrap_plots(gg0 + ggtitle("Histogram of observations"), 
           gg1 + ggtitle("Two-component mixture density")#, 
           #gg2+ggtitle("Histogram of more than two components")
           )
dev.off()
```

# Model-based clustering

## Clustering faithful data using Mclust
```{r}
library(mclust)
data(faithful)
head(faithful)

# fit Gaussian mixture model 
faithfulMclust <- Mclust(faithful)

summary(faithfulMclust)

# In this case, the best model is chosen according to BIC

# detailed summary including the estimated parameters
summary(faithfulMclust, parameters = TRUE)

# plot the results
plot(faithfulMclust)
```

# Examples with the geyser data in the lecture
```{r}
data(geyser, package="MASS")
x <- cbind(geyser$duration, geyser$waiting)
geyserMclust <- Mclust(x)

plot(geyserMclust)

# get BIC 
geyserBIC <- mclustBIC(x)
plot(geyserBIC)

geyserModel <- mclustModel(x, geyserBIC, G=3:4,
            modelNames=c("VVI", "EEE"))

## generate plots individually 
# surfacePlot
surfacePlot(x, parameters=geyserModel$parameters,
            type="contour", what="density",
            transformation="none", drawlabels=FALSE)

# 2D plot
mclust2Dplot(x, parameters=geyserModel$parameters,
             z=geyserModel$z, what="classification"
             )
mclust2Dplot(x, parameters=geyserModel$parameters,
             z=geyserModel$z, what="uncertainty"
             )

```
